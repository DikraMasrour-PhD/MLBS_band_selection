{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import scipy.io as sio\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing constants\n",
    "DATASET_NAME = 'IP'\n",
    "K = 10\n",
    "K_NUM = 1\n",
    "\n",
    "# The ratio of the training dataset over the whole points.\n",
    "TRAINING_RATIO = 0.25                        \n",
    "pmask_slope = 5\n",
    "sample_slope = 10\n",
    "BS = 30\n",
    "\n",
    "EPOCHS = 200\n",
    "LR = 0.001\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "\"\"\" Data preprocessing functions \"\"\"\n",
    "def read_data(dataset_name):                        # Loads Dataset\n",
    "    # path = os.getcwd()\n",
    "    if dataset_name == 'IP':\n",
    "        image = sio.loadmat(\"..\\\\source_code\\\\datasets\\\\IndianPines\\\\Indian_pines_corrected.mat\")[\"indian_pines_corrected\"]\n",
    "        label = sio.loadmat(\"..\\\\source_code\\\\datasets\\\\IndianPines\\\\Indian_pines_gt.mat\")[\"indian_pines_gt\"]\n",
    "    elif dataset_name == 'UP':\n",
    "        image = sio.loadmat('..\\\\source_code\\\\datasets\\\\PaviaUniversity\\\\PaviaU.mat')['paviaU']\n",
    "        label = sio.loadmat('..\\\\source_code\\\\datasets\\\\PaviaUniversity\\\\PaviaU_gt.mat')['paviaU_gt']\n",
    "    image = np.float64(image)\n",
    "    label = np.array(label).astype(float)\n",
    "    return image, label\n",
    "\n",
    "def normalize_dataset(data):                        # Dataset Min-Max Normalization\n",
    "    max_val = np.amax(data, axis=(0,1,2))\n",
    "    min_val = np.amin(data, axis=(0,1,2))\n",
    "    data_norm = (data - min_val) / (max_val - min_val)\n",
    "    return data_norm\n",
    "\n",
    "# Separates the dataset into training and test sets\n",
    "# ! Pretty much useless method\n",
    "def separate_train_test(data, labels, p):   \n",
    "    '''\n",
    "    data: HSI image (x, y, z), x and y being pixel coordinates and z being the number of spectral bands\n",
    "    labels: pixels labels matrix as provided in dataset\n",
    "    p: proportion (ratio) of training set\n",
    "    '''\n",
    "    c = int(labels.max())\n",
    "    x = np.array([], dtype=float).reshape(-1, data.shape[2])\n",
    "    xb = []\n",
    "    x_loc1 = []\n",
    "    x_loc2 = []\n",
    "    x_loc = []\n",
    "    y = np.array([], dtype=float).reshape(-1, data.shape[2])\n",
    "    yb = []\n",
    "    y_loc1 = []\n",
    "    y_loc2 = []\n",
    "    y_loc = []\n",
    "    for i in range(1, c+1):\n",
    "        # label coordinates\n",
    "        loc1, loc2 = np.where(labels == i)\n",
    "        # label frequency\n",
    "        num = len(loc1)                     \n",
    "        order = np.random.permutation(range(num))\n",
    "        loc1 = loc1[order]\n",
    "        loc2 = loc2[order]\n",
    "        # number of training samples to be selected for each label\n",
    "        num1 = int(np.round(num*p))\n",
    "        x = np.vstack([x, data[loc1[:num1], loc2[:num1], :]])\n",
    "        y = np.vstack([y, data[loc1[num1:], loc2[num1:], :]])\n",
    "        xb.extend([i]*num1)\n",
    "        yb.extend([i]*(num-num1))\n",
    "        x_loc1.extend(loc1[:num1])\n",
    "        x_loc2.extend(loc2[:num1])\n",
    "        y_loc1.extend(loc1[num1:])\n",
    "        y_loc2.extend(loc2[num1:])\n",
    "        x_loc = np.vstack([x_loc1, x_loc2])\n",
    "        y_loc = np.vstack([y_loc1, y_loc2])\n",
    "    return x, xb, x_loc, y, yb, y_loc\n",
    "\n",
    "def one_hot(lable,class_number):            # One-hot converter\n",
    "    one_hot_array = np.zeros([len(lable),class_number])\n",
    "    for i in range(len(lable)):\n",
    "        one_hot_array[i,int(lable[i]-1)] = 1\n",
    "    return one_hot_array\n",
    "\n",
    "def disorder(X,Y,loc):\n",
    "    index_train = np.arange(X.shape[0])\n",
    "    np.random.shuffle(index_train)\n",
    "    X = X[index_train, :]\n",
    "    Y = Y[index_train, :]\n",
    "    loc = loc[:,index_train]\n",
    "    return X,Y,loc\n",
    "\n",
    "# when w=1, windowFeature performs a train/test split\n",
    "def windowFeature(data, loc, w):\n",
    "    size = np.shape(data)\n",
    "    data_expand = np.zeros((int(size[0]+w-1),int(size[1]+w-1),size[2]))\n",
    "    newdata = np.zeros((len(loc[0]), w, w,size[2]))\n",
    "    # for each spectral band\n",
    "    for j in range(size[2]):    \n",
    "        data_expand[:,:,j] = np.lib.pad(data[:,:,j], ((int(w / 2), int(w / 2)), (int(w / 2),int(w / 2))), 'symmetric')\n",
    "        newdata[:,:,:,j] = np.zeros((len(loc[0]), w, w))\n",
    "        # for each training sample\n",
    "        for i in range(len(loc[0])):\n",
    "            loc1 = loc[0][i]\n",
    "            loc2 = loc[1][i]\n",
    "            f = data_expand[loc1:loc1 + w, loc2:loc2 + w,j]\n",
    "            newdata[i, :, :,j] = f\n",
    "    return newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions of the probability mask as described in the paper.\n",
    "Each weight is passed into a sigmoid to convert them to a probability representation.\n",
    "\"\"\"\n",
    "class ProbMask(tf.keras.layers.Layer):\n",
    "    def __init__(self, slope, filter_size, **kwargs):\n",
    "        self.slope = tf.Variable(slope, dtype=tf.float32)\n",
    "        self.P = filter_size\n",
    "        \n",
    "        # ? Paper says V is intialised from a Normal Distribution ?\n",
    "        w_init = tf.random_uniform_initializer(minval=0, maxval=1)\n",
    "        # w_init = tf.random_normal_initializer(mean=0, stddev=1)\n",
    "        self.w = tf.Variable(w_init(shape=(1, filter_size, 1)))\n",
    "        print('w1', self.w)\n",
    "        # Inverse Tranform Sampling (https://en.wikipedia.org/wiki/Inverse_transform_sampling)\n",
    "        self.w = tf.Variable(- tf.math.log(1. / self.w - 1.) / self.slope)\n",
    "        print('w2', self.w)\n",
    "        super(ProbMask, self).__init__(**kwargs) \n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        super(ProbMask, self).build(input_shape)\n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "        weights = self.w\n",
    "        # return weights\n",
    "        return tf.sigmoid(self.slope * weights)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        lst = list(input_shape)\n",
    "        lst[-1] = 1\n",
    "        return tuple(lst)\n",
    "    \n",
    "# (Normalisation layer) rescales the weights given a sparsity level in probability map.\n",
    "class RescaleProbMask(tf.keras.layers.Layer):\n",
    "    def __init__(self, sparsity, **kwargs):\n",
    "        self.alpha = tf.constant(sparsity, dtype=tf.float32)\n",
    "        super(RescaleProbMask, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.num = input_shape[2]\n",
    "        super(RescaleProbMask, self).build(input_shape)\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        prob_map = self.force_sparsity(input_tensor, alpha = self.alpha)\n",
    "        return prob_map\n",
    "\n",
    "    # Paper: Sec3.1: Eq(5): making opt prob unconstrained\n",
    "    def force_sparsity(self, pixel, alpha):\n",
    "        p = tf.math.reduce_mean(pixel, axis=1)\n",
    "        beta = (1 - alpha) / (1 - p)\n",
    "        le = tf.cast(tf.greater_equal(p, alpha), tf.float32)\n",
    "        return (le * pixel * alpha) / p + (1 - le) * (1 - beta * (1 - pixel))\n",
    "\n",
    "class ThresholdRandomMask(tf.keras.layers.Layer):\n",
    "    def __init__(self, slope = 12, **kwargs):\n",
    "        self.slope = None\n",
    "        if slope is not None:\n",
    "            self.slope = tf.Variable(slope, dtype=tf.float32) \n",
    "        super(ThresholdRandomMask, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        filter_size = input_shape[1]\n",
    "        t_init = tf.random_uniform_initializer(minval=0, maxval=1)\n",
    "        threshold = tf.constant(t_init(shape=(1, filter_size, 1)))\n",
    "        self.thresh = threshold\n",
    "        super(ThresholdRandomMask, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #thresh = tf.zeros_like(inputs)\n",
    "        if self.slope is not None:\n",
    "            return tf.sigmoid(self.slope * (inputs-self.thresh)) \n",
    "        else:  \n",
    "            # INFERENCE \n",
    "            return inputs > self.thresh\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n",
    "\n",
    "# The layer that performs masking operation.\n",
    "class UnderSample(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(UnderSample, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(UnderSample, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_pix = inputs[0]\n",
    "        mask = inputs[1]\n",
    "        image_masked = tf.multiply(input_pix, mask)\n",
    "        return image_masked\n",
    "\n",
    "# Learning rate scheduler \n",
    "def scheduler(epoch, lr):\n",
    "    if epoch == 100:\n",
    "        lr = lr / 10\n",
    "    if epoch == 150:\n",
    "        lr = lr / 10\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing and modifying data\n",
    "data_ori, labels_ori = read_data(DATASET_NAME)\n",
    "\n",
    "train_x, train_y, train_loc, test_x, test_y, test_loc = separate_train_test(data_ori, labels_ori, TRAINING_RATIO)\n",
    "\n",
    "# number of classes\n",
    "num_classification = int(np.max(labels_ori))\n",
    "num_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2562, 1, 1, 200), (7687, 1, 1, 200))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = windowFeature(data_ori, train_loc, 1)\n",
    "X_test = windowFeature(data_ori, test_loc, 1)\n",
    "X_train.shape, X_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalisation (after splitting)\n",
    "X_train_norm = normalize_dataset(X_train)\n",
    "X_test_norm = normalize_dataset(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.squeeze(X_train_norm, axis=2)\n",
    "X_test = np.squeeze(X_test_norm, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2562, 16), (7687, 16))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = one_hot(train_y,num_classification)\n",
    "Y_train_int = np.argmax(Y_train, axis=1)\n",
    "Y_test = one_hot(test_y,num_classification)\n",
    "Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, train_loc = disorder(X_train, Y_train, train_loc)\n",
    "X_test, Y_test, test_loc = disorder(X_test, Y_test, test_loc)\n",
    "\n",
    "X_train = np.transpose(X_train, axes=(0,2,1))\n",
    "X_test = np.transpose(X_test, axes=(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2562, 200, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training images:  (200, 1)\n",
      "Shape of the test images:  (200, 1)\n",
      "Number of the train samples 2562\n",
      "Number of the test samples 7687\n",
      "Number of the classes 16\n",
      "Class weights dict {0: 38.506837354843995, 1: 7.059831985699054, 2: 9.2490431617559, 3: 17.366106809231667, 4: 12.12650886134199, 5: 9.887643047649991, 6: 50.41728484340734, 7: 12.17693115309604, 8: 59.65453591617137, 9: 8.557074967743109, 10: 5.383246764527845, 11: 10.964721769947355, 12: 18.678559732059004, 13: 7.503863620202448, 14: 13.614222907828822, 15: 27.81407078758715}\n"
     ]
    }
   ],
   "source": [
    "# Number of training samples (training pixels)\n",
    "num_data = X_train.shape[0]  \n",
    "# Number of bands\n",
    "num_band = X_train.shape[1]   \n",
    "# Number of classes          \n",
    "num_class = Y_train.shape[1]\n",
    "\n",
    "number_class_label = []; class_weights = []\n",
    "for i in range(num_class):\n",
    "    # per class frequency in training set\n",
    "    number_class_label.append(len(np.where(Y_train_int == i)[0]))\n",
    "    # weight given to class i\n",
    "    class_weights.append(num_data/number_class_label[i])\n",
    "\n",
    "class_weights = np.array(class_weights)\n",
    "class_weights_norm = class_weights / np.sum(class_weights)\n",
    "class_weights_norm = np.sqrt(class_weights_norm)\n",
    "# class_weights_norm = np.square(class_weights_norm)\n",
    "class_weights_dic = {}\n",
    "for i in range(num_class):\n",
    "    class_weights_dic[i] = 100 * class_weights_norm[i]\n",
    "\n",
    "print('Shape of the training images: ', X_train[0].shape)\n",
    "print('Shape of the test images: ', X_test[0].shape)\n",
    "print('Number of the train samples', X_train.shape[0])\n",
    "print('Number of the test samples', X_test.shape[0])\n",
    "print('Number of the classes', num_classification)\n",
    "print('Class weights dict', class_weights_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 <tf.Variable 'Variable:0' shape=(1, 200, 1) dtype=float32, numpy=\n",
      "array([[[8.5914373e-02],\n",
      "        [5.1298463e-01],\n",
      "        [3.5321200e-01],\n",
      "        [5.1235318e-01],\n",
      "        [1.3836777e-01],\n",
      "        [7.0760131e-02],\n",
      "        [2.8034663e-01],\n",
      "        [4.5623672e-01],\n",
      "        [6.7400098e-01],\n",
      "        [3.0862486e-01],\n",
      "        [5.8917201e-01],\n",
      "        [8.9967906e-01],\n",
      "        [9.7280550e-01],\n",
      "        [1.0548127e-01],\n",
      "        [4.1237819e-01],\n",
      "        [4.1309285e-01],\n",
      "        [6.7453384e-01],\n",
      "        [4.5877862e-01],\n",
      "        [1.1039436e-01],\n",
      "        [4.3892705e-01],\n",
      "        [1.6875255e-01],\n",
      "        [9.7054994e-01],\n",
      "        [9.7398973e-01],\n",
      "        [3.8829815e-01],\n",
      "        [4.2403424e-01],\n",
      "        [9.1588962e-01],\n",
      "        [4.4726133e-01],\n",
      "        [2.5295496e-02],\n",
      "        [2.6717722e-01],\n",
      "        [9.4124722e-01],\n",
      "        [5.9784305e-01],\n",
      "        [4.2479229e-01],\n",
      "        [3.7464917e-01],\n",
      "        [5.2407384e-01],\n",
      "        [4.0169990e-01],\n",
      "        [4.7934210e-01],\n",
      "        [2.8452659e-01],\n",
      "        [2.0860612e-01],\n",
      "        [4.8814142e-01],\n",
      "        [2.2899628e-01],\n",
      "        [5.9432626e-02],\n",
      "        [4.3246853e-01],\n",
      "        [9.3944514e-01],\n",
      "        [2.5023162e-01],\n",
      "        [1.2803197e-01],\n",
      "        [7.0474052e-01],\n",
      "        [9.0572250e-01],\n",
      "        [8.5855174e-01],\n",
      "        [6.4446974e-01],\n",
      "        [8.7320411e-01],\n",
      "        [4.3192470e-01],\n",
      "        [1.7614949e-01],\n",
      "        [9.3115962e-01],\n",
      "        [9.5061934e-01],\n",
      "        [4.1106832e-01],\n",
      "        [2.8126788e-01],\n",
      "        [2.4363959e-01],\n",
      "        [7.0906723e-01],\n",
      "        [6.0554790e-01],\n",
      "        [6.6003847e-01],\n",
      "        [3.5150528e-02],\n",
      "        [7.4251246e-01],\n",
      "        [9.6734166e-01],\n",
      "        [9.2588472e-01],\n",
      "        [3.9475965e-01],\n",
      "        [8.8253057e-01],\n",
      "        [9.9051833e-02],\n",
      "        [2.6533616e-01],\n",
      "        [3.8277173e-01],\n",
      "        [8.5806441e-01],\n",
      "        [4.4893026e-01],\n",
      "        [5.3537643e-01],\n",
      "        [5.2908385e-01],\n",
      "        [1.2542999e-01],\n",
      "        [8.5073698e-01],\n",
      "        [3.7654698e-01],\n",
      "        [5.4512048e-01],\n",
      "        [4.1933930e-01],\n",
      "        [7.2791600e-01],\n",
      "        [8.2453942e-01],\n",
      "        [5.3837144e-01],\n",
      "        [1.1956084e-01],\n",
      "        [4.7637558e-01],\n",
      "        [7.0137811e-01],\n",
      "        [5.5378568e-01],\n",
      "        [4.2150295e-01],\n",
      "        [9.7970152e-01],\n",
      "        [5.2942038e-03],\n",
      "        [9.4346023e-01],\n",
      "        [1.3177836e-01],\n",
      "        [3.9398253e-01],\n",
      "        [7.8748107e-01],\n",
      "        [9.2506409e-05],\n",
      "        [6.5812421e-01],\n",
      "        [9.1836905e-01],\n",
      "        [8.8374448e-01],\n",
      "        [3.2624114e-01],\n",
      "        [2.1739244e-02],\n",
      "        [8.3512127e-01],\n",
      "        [8.6848760e-01],\n",
      "        [4.9882770e-02],\n",
      "        [5.9950495e-01],\n",
      "        [2.7747273e-02],\n",
      "        [7.6776588e-01],\n",
      "        [9.0343654e-01],\n",
      "        [9.8265910e-01],\n",
      "        [5.8658278e-01],\n",
      "        [7.1936989e-01],\n",
      "        [3.7156641e-01],\n",
      "        [4.6437705e-01],\n",
      "        [4.6159136e-01],\n",
      "        [9.6916199e-01],\n",
      "        [3.7022066e-01],\n",
      "        [5.4202819e-01],\n",
      "        [9.7633886e-01],\n",
      "        [9.3972886e-01],\n",
      "        [1.8433487e-01],\n",
      "        [2.3569286e-01],\n",
      "        [2.6495278e-01],\n",
      "        [7.7984047e-01],\n",
      "        [7.7805841e-01],\n",
      "        [5.3999639e-01],\n",
      "        [4.6295142e-01],\n",
      "        [5.0483084e-01],\n",
      "        [6.8715298e-01],\n",
      "        [5.9500730e-01],\n",
      "        [6.0288906e-02],\n",
      "        [4.6361518e-01],\n",
      "        [1.1808264e-01],\n",
      "        [5.3346145e-01],\n",
      "        [2.6652908e-01],\n",
      "        [2.3968613e-01],\n",
      "        [1.6446304e-01],\n",
      "        [8.2624352e-01],\n",
      "        [1.8850005e-01],\n",
      "        [4.1506660e-01],\n",
      "        [9.6372592e-01],\n",
      "        [4.8442006e-02],\n",
      "        [7.4602044e-01],\n",
      "        [2.5884449e-01],\n",
      "        [3.3722210e-01],\n",
      "        [3.9780021e-02],\n",
      "        [5.4896617e-01],\n",
      "        [2.9109681e-01],\n",
      "        [5.8583856e-02],\n",
      "        [3.6161351e-01],\n",
      "        [1.7770004e-01],\n",
      "        [5.4611158e-01],\n",
      "        [3.2725894e-01],\n",
      "        [9.2657995e-01],\n",
      "        [5.3916681e-01],\n",
      "        [7.0097506e-01],\n",
      "        [2.9560983e-01],\n",
      "        [8.7390637e-01],\n",
      "        [8.5329521e-01],\n",
      "        [6.7042410e-01],\n",
      "        [9.0518415e-01],\n",
      "        [9.9095559e-01],\n",
      "        [8.1046641e-01],\n",
      "        [4.9889076e-01],\n",
      "        [9.1090846e-01],\n",
      "        [3.5263133e-01],\n",
      "        [6.8849492e-01],\n",
      "        [2.5362766e-01],\n",
      "        [1.0465980e-02],\n",
      "        [7.9430413e-01],\n",
      "        [3.3477461e-01],\n",
      "        [2.0680439e-01],\n",
      "        [6.2173367e-01],\n",
      "        [5.6509161e-01],\n",
      "        [4.0573442e-01],\n",
      "        [7.1885085e-01],\n",
      "        [4.2863560e-01],\n",
      "        [4.2420816e-01],\n",
      "        [3.4073734e-01],\n",
      "        [6.7912781e-01],\n",
      "        [9.4281220e-01],\n",
      "        [3.8058114e-01],\n",
      "        [1.8880141e-01],\n",
      "        [7.7216148e-01],\n",
      "        [8.5964692e-01],\n",
      "        [2.9837954e-01],\n",
      "        [3.8680112e-01],\n",
      "        [3.7531948e-01],\n",
      "        [5.5904388e-02],\n",
      "        [2.3875356e-02],\n",
      "        [9.3645978e-01],\n",
      "        [4.2482507e-01],\n",
      "        [9.3319488e-01],\n",
      "        [1.7063975e-02],\n",
      "        [1.2737286e-01],\n",
      "        [4.2245555e-01],\n",
      "        [8.3559632e-02],\n",
      "        [6.3990104e-01],\n",
      "        [6.3765264e-01],\n",
      "        [9.7836852e-01],\n",
      "        [6.4175129e-01],\n",
      "        [8.6765528e-02],\n",
      "        [4.1065133e-01],\n",
      "        [2.8942680e-01]]], dtype=float32)>\n",
      "w2 <tf.Variable 'Variable:0' shape=(1, 200, 1) dtype=float32, numpy=\n",
      "array([[[-4.72914606e-01],\n",
      "        [ 1.03900488e-02],\n",
      "        [-1.20990016e-01],\n",
      "        [ 9.88455582e-03],\n",
      "        [-3.65782678e-01],\n",
      "        [-5.15014231e-01],\n",
      "        [-1.88548580e-01],\n",
      "        [-3.51004526e-02],\n",
      "        [ 1.45267427e-01],\n",
      "        [-1.61311194e-01],\n",
      "        [ 7.21087009e-02],\n",
      "        [ 4.38732803e-01],\n",
      "        [ 7.15434015e-01],\n",
      "        [-4.27550495e-01],\n",
      "        [-7.08285421e-02],\n",
      "        [-7.02388436e-02],\n",
      "        [ 1.45752668e-01],\n",
      "        [-3.30521390e-02],\n",
      "        [-4.17343855e-01],\n",
      "        [-4.91035357e-02],\n",
      "        [-3.18898827e-01],\n",
      "        [ 6.99033618e-01],\n",
      "        [ 7.24581599e-01],\n",
      "        [-9.08942968e-02],\n",
      "        [-6.12468123e-02],\n",
      "        [ 4.77553070e-01],\n",
      "        [-4.23484519e-02],\n",
      "        [-7.30301619e-01],\n",
      "        [-2.01798350e-01],\n",
      "        [ 5.54773450e-01],\n",
      "        [ 7.92971775e-02],\n",
      "        [-6.06261678e-02],\n",
      "        [-1.02464542e-01],\n",
      "        [ 1.92739833e-02],\n",
      "        [-7.96774477e-02],\n",
      "        [-1.65357105e-02],\n",
      "        [-1.84423536e-01],\n",
      "        [-2.66669571e-01],\n",
      "        [-9.48863290e-03],\n",
      "        [-2.42797494e-01],\n",
      "        [-5.52327991e-01],\n",
      "        [-5.43573126e-02],\n",
      "        [ 5.48347831e-01],\n",
      "        [-2.19475463e-01],\n",
      "        [-3.83694559e-01],\n",
      "        [ 1.73995003e-01],\n",
      "        [ 4.52498108e-01],\n",
      "        [ 3.60662639e-01],\n",
      "        [ 1.18963480e-01],\n",
      "        [ 3.85918111e-01],\n",
      "        [-5.48005588e-02],\n",
      "        [-3.08531225e-01],\n",
      "        [ 5.20927906e-01],\n",
      "        [ 5.91510892e-01],\n",
      "        [-7.19101503e-02],\n",
      "        [-1.87636226e-01],\n",
      "        [-2.26565599e-01],\n",
      "        [ 1.78171650e-01],\n",
      "        [ 8.57271999e-02],\n",
      "        [ 1.32693142e-01],\n",
      "        [-6.62466466e-01],\n",
      "        [ 2.11813658e-01],\n",
      "        [ 6.77690387e-01],\n",
      "        [ 5.05025566e-01],\n",
      "        [-8.54697078e-02],\n",
      "        [ 4.03322995e-01],\n",
      "        [-4.41560894e-01],\n",
      "        [-2.03683093e-01],\n",
      "        [-9.55600217e-02],\n",
      "        [ 3.59861225e-01],\n",
      "        [-4.09987457e-02],\n",
      "        [ 2.83484999e-02],\n",
      "        [ 2.32933722e-02],\n",
      "        [-3.88396919e-01],\n",
      "        [ 3.48078668e-01],\n",
      "        [-1.00846127e-01],\n",
      "        [ 3.61948609e-02],\n",
      "        [-6.50972277e-02],\n",
      "        [ 1.96814969e-01],\n",
      "        [ 3.09482157e-01],\n",
      "        [ 3.07576451e-02],\n",
      "        [-3.99319112e-01],\n",
      "        [-1.89136248e-02],\n",
      "        [ 1.70773804e-01],\n",
      "        [ 4.31956649e-02],\n",
      "        [-6.33213520e-02],\n",
      "        [ 7.75340319e-01],\n",
      "        [-1.04716694e+00],\n",
      "        [ 5.62922120e-01],\n",
      "        [-3.77065122e-01],\n",
      "        [-8.61204639e-02],\n",
      "        [ 2.61961639e-01],\n",
      "        [-1.85762811e+00],\n",
      "        [ 1.30989254e-01],\n",
      "        [ 4.84078228e-01],\n",
      "        [ 4.05675560e-01],\n",
      "        [-1.45047098e-01],\n",
      "        [-7.61331439e-01],\n",
      "        [ 3.24473381e-01],\n",
      "        [ 3.77530426e-01],\n",
      "        [-5.89381933e-01],\n",
      "        [ 8.06805789e-02],\n",
      "        [-7.11295664e-01],\n",
      "        [ 2.39147812e-01],\n",
      "        [ 4.47201103e-01],\n",
      "        [ 8.07438970e-01],\n",
      "        [ 6.99713230e-02],\n",
      "        [ 1.88267618e-01],\n",
      "        [-1.05100557e-01],\n",
      "        [-2.85467356e-02],\n",
      "        [-3.07875536e-02],\n",
      "        [ 6.89536929e-01],\n",
      "        [-1.06254056e-01],\n",
      "        [ 3.37020680e-02],\n",
      "        [ 7.43995309e-01],\n",
      "        [ 5.49347579e-01],\n",
      "        [-2.97449976e-01],\n",
      "        [-2.35288054e-01],\n",
      "        [-2.04076618e-01],\n",
      "        [ 2.52947390e-01],\n",
      "        [ 2.50877470e-01],\n",
      "        [ 3.20656262e-02],\n",
      "        [-2.96932608e-02],\n",
      "        [ 3.86479311e-03],\n",
      "        [ 1.57368511e-01],\n",
      "        [ 7.69409165e-02],\n",
      "        [-5.49284875e-01],\n",
      "        [-2.91593820e-02],\n",
      "        [-4.02142704e-01],\n",
      "        [ 2.68092193e-02],\n",
      "        [-2.02460915e-01],\n",
      "        [-2.30880216e-01],\n",
      "        [-3.25077713e-01],\n",
      "        [ 3.11846912e-01],\n",
      "        [-2.91957200e-01],\n",
      "        [-6.86118081e-02],\n",
      "        [ 6.55940890e-01],\n",
      "        [-5.95546663e-01],\n",
      "        [ 2.15499833e-01],\n",
      "        [-2.10396618e-01],\n",
      "        [-1.35139644e-01],\n",
      "        [-6.36759520e-01],\n",
      "        [ 3.92988808e-02],\n",
      "        [-1.78012624e-01],\n",
      "        [-5.55385232e-01],\n",
      "        [-1.13673590e-01],\n",
      "        [-3.06401640e-01],\n",
      "        [ 3.69943753e-02],\n",
      "        [-1.44121766e-01],\n",
      "        [ 5.07060647e-01],\n",
      "        [ 3.13977785e-02],\n",
      "        [ 1.70389086e-01],\n",
      "        [-1.73658401e-01],\n",
      "        [ 3.87189686e-01],\n",
      "        [ 3.52136672e-01],\n",
      "        [ 1.42020777e-01],\n",
      "        [ 4.51240450e-01],\n",
      "        [ 9.39305782e-01],\n",
      "        [ 2.90608764e-01],\n",
      "        [-8.87377537e-04],\n",
      "        [ 4.64955628e-01],\n",
      "        [-1.21498562e-01],\n",
      "        [ 1.58618480e-01],\n",
      "        [-2.15871483e-01],\n",
      "        [-9.09820855e-01],\n",
      "        [ 2.70213544e-01],\n",
      "        [-1.37333691e-01],\n",
      "        [-2.68859297e-01],\n",
      "        [ 9.93826687e-02],\n",
      "        [ 5.23704812e-02],\n",
      "        [-7.63254985e-02],\n",
      "        [ 1.87753752e-01],\n",
      "        [-5.74840009e-02],\n",
      "        [-6.11043759e-02],\n",
      "        [-1.32002026e-01],\n",
      "        [ 1.49953306e-01],\n",
      "        [ 5.60505152e-01],\n",
      "        [-9.74164754e-02],\n",
      "        [-2.91563451e-01],\n",
      "        [ 2.44111329e-01],\n",
      "        [ 3.62472057e-01],\n",
      "        [-1.71005249e-01],\n",
      "        [-9.21557173e-02],\n",
      "        [-1.01892553e-01],\n",
      "        [-5.65316916e-01],\n",
      "        [-7.42148697e-01],\n",
      "        [ 5.38086653e-01],\n",
      "        [-6.05993457e-02],\n",
      "        [ 5.27366757e-01],\n",
      "        [-8.10714900e-01],\n",
      "        [-3.84877950e-01],\n",
      "        [-6.25402182e-02],\n",
      "        [-4.78987306e-01],\n",
      "        [ 1.14986934e-01],\n",
      "        [ 1.13038078e-01],\n",
      "        [ 7.62347341e-01],\n",
      "        [ 1.16594695e-01],\n",
      "        [-4.70756620e-01],\n",
      "        [-7.22546950e-02],\n",
      "        [-1.79633901e-01]]], dtype=float32)>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling layer \"rescaled_mask\" (type RescaleProbMask).\n\nin user code:\n\n    File \"C:\\Users\\zbook\\AppData\\Local\\Temp\\ipykernel_20840\\383605807.py\", line 45, in call  *\n        out = prob_map.numpy()\n\n    AttributeError: 'Tensor' object has no attribute 'numpy'\n\n\nCall arguments received by layer \"rescaled_mask\" (type RescaleProbMask):\n  • input_tensor=tf.Tensor(shape=(1, 200, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m input_image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(num_band, \u001b[38;5;241m1\u001b[39m), name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_image\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m prob_mask_tensor \u001b[38;5;241m=\u001b[39m ProbMask(slope\u001b[38;5;241m=\u001b[39mpmask_slope, filter_size\u001b[38;5;241m=\u001b[39mnum_band, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprob_mask\u001b[39m\u001b[38;5;124m'\u001b[39m)(input_image)\n\u001b[1;32m----> 5\u001b[0m thresh_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mRescaleProbMask\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparsity\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBS\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mnum_band\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrescaled_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprob_mask_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# tensor_mask = ThresholdRandomMask(slope = sample_slope, name='sampled_mask')(thresh_tensor) \u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# last_tensor = UnderSample(name='proxy_data')([input_image, tensor_mask])\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zbook\\anaconda3_new\\envs\\band_selection_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file_ylkbxtn.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, input_tensor)\u001b[0m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m     10\u001b[0m prob_map \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mforce_sparsity, (ag__\u001b[38;5;241m.\u001b[39mld(input_tensor),), \u001b[38;5;28mdict\u001b[39m(alpha\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39malpha), fscope)\n\u001b[1;32m---> 11\u001b[0m out \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprob_map\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mprint\u001b[39m)(ag__\u001b[38;5;241m.\u001b[39mld(out))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: Exception encountered when calling layer \"rescaled_mask\" (type RescaleProbMask).\n\nin user code:\n\n    File \"C:\\Users\\zbook\\AppData\\Local\\Temp\\ipykernel_20840\\383605807.py\", line 45, in call  *\n        out = prob_map.numpy()\n\n    AttributeError: 'Tensor' object has no attribute 'numpy'\n\n\nCall arguments received by layer \"rescaled_mask\" (type RescaleProbMask):\n  • input_tensor=tf.Tensor(shape=(1, 200, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# Code for model creation, compilation and training.\n",
    "input_image = tf.keras.Input(shape=(num_band, 1), name = 'input_image')\n",
    "\n",
    "prob_mask_tensor = ProbMask(slope=pmask_slope, filter_size=num_band, name='prob_mask')(input_image)\n",
    "thresh_tensor = RescaleProbMask(sparsity = BS/num_band, name='rescaled_mask')(prob_mask_tensor)\n",
    "tensor_mask = ThresholdRandomMask(slope = sample_slope, name='sampled_mask')(thresh_tensor) \n",
    "last_tensor = UnderSample(name='proxy_data')([input_image, tensor_mask])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
